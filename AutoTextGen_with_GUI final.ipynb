{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SilLTsmNFFfz"
   },
   "source": [
    "Token Dictionary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1dD2pQFIqwcY"
   },
   "outputs": [],
   "source": [
    "def build_dict():\n",
    "  \n",
    "  import requests\n",
    "  \n",
    "  # Corpus -> The Project Gutenberg EBook of The Art Of Writing & Speaking The English Language, by Sherwin Cody\n",
    "  import_dataset=requests.get('http://www.gutenberg.org/files/19719/19719-0.txt')\n",
    "\n",
    "  data = import_dataset.text.split('\\n')\n",
    "  data=\" \".join(data)\n",
    "\n",
    "  #Cleaning the text and separating each word into a list\n",
    "  tokens = [w.translate(table) for w in data.split()]\n",
    "  tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "  #Length of training sequence one greater than input sequence\n",
    "  length = seq_length + 1\n",
    "  lines= []\n",
    "\n",
    "  for i in range(length, len(tokens)+1):\n",
    "    seq = tokens[i-length:i]\n",
    "    line = ' '.join(seq)\n",
    "    lines.append(line)\n",
    "\n",
    "  import numpy as np\n",
    "  from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "  tokenizer= Tokenizer()\n",
    "  tokenizer.fit_on_texts(lines)\n",
    "  sequences = tokenizer.texts_to_sequences(lines)\n",
    "\n",
    "  token_dict=pd.DataFrame(tokenizer.word_index.values(),\n",
    "                          tokenizer.word_index.keys(), ['value'])\n",
    "  token_dict.to_csv('TD.csv')\n",
    "  return token_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyZB_kgaE4yC"
   },
   "source": [
    "Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Snn1h-76YBNT"
   },
   "outputs": [],
   "source": [
    "def built_model():\n",
    "  \n",
    "  from tensorflow.keras.utils import to_categorical\n",
    "  from tensorflow.keras.models import Sequential\n",
    "  from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "  \n",
    "  #Preparaton of dataset for training\n",
    "  sequences = np.array(sequences)\n",
    "  X, y = sequences[:, :-1], sequences[:,-1]\n",
    "  vocab_size = len(tokenizer.word_index)+1\n",
    "  y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "  #Building the model\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "  model.add(LSTM(100, return_sequences = True))\n",
    "  model.add(LSTM(100))\n",
    "  model.add(Dense(100, activation='relu'))\n",
    "  model.add(Dense(vocab_size, activation='softmax')) \n",
    "  model.compile(loss = 'categorical_crossentropy',\n",
    "                optimizer = 'adam', metrics = 'accuracy')\n",
    "\n",
    "  #Training and Saving the model\n",
    "  model.fit(X, y, batch_size=256, epochs=200)\n",
    "  model.save('ATG.h5')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmz3KHG2Elt8"
   },
   "source": [
    "Loading Token Dictionary and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QYyypJn3zBP2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tkinter import *\n",
    "\n",
    "table=str.maketrans('', '', string.punctuation)\n",
    "matrix=np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DkZArEC_8UNf"
   },
   "outputs": [],
   "source": [
    "seq_length=3\n",
    "try:\n",
    "  model = load_model('ATG.h5')\n",
    "except OSError:\n",
    "  token_dict = build_dict()\n",
    "  model = built_model()\n",
    "\n",
    "try:\n",
    "  token_dict = pd.read_csv('TD.csv',index_col=0)\n",
    "except FileNotFoundError:\n",
    "  token_dict = build_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcTuYj_JEdA7"
   },
   "source": [
    "Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AkPbFvye0Zji"
   },
   "outputs": [],
   "source": [
    "def prediction(data):\n",
    "  global matrix\n",
    "  input_text=[w.translate(table) for w in data.split()]\n",
    "  input_text=[w.lower() for w in input_text if w.isalpha()]\n",
    "  encoded=[]\n",
    "  for w in input_text:\n",
    "    try:\n",
    "      encoded.append(token_dict.value[w])\n",
    "    except KeyError:\n",
    "      None\n",
    "  \n",
    "  encoded = pad_sequences([encoded], maxlen = seq_length)\n",
    "  matrix = model.predict(encoded)[0]\n",
    "  \n",
    "def next_word(input_text):\n",
    "    global matrix\n",
    "    prediction(input_text)\n",
    "    predicted=[]\n",
    "    matrix_copy=matrix.copy()\n",
    "    for _ in range(5):\n",
    "      if matrix_copy.max()<0.05:\n",
    "        break\n",
    "      y_maxp=matrix_copy.argmax()\n",
    "      predicted.append(token_dict.index[y_maxp-1])\n",
    "      matrix_copy[y_maxp]=0\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fskdH-S6YO6b"
   },
   "outputs": [],
   "source": [
    "def curr_word(input_text):\n",
    "  try:\n",
    "      word=input_text.split()[-1]\n",
    "      global matrix\n",
    "      word_list=[w for w in list(token_dict.index) if w.startswith(word)]\n",
    "      token_list=[token_dict.value[w] for w in word_list]\n",
    "      prob_list=np.array([matrix[w] for w in token_list])\n",
    "      suggestion=[]\n",
    "      for _ in range(np.array([3,len(word_list)]).min()):\n",
    "        if prob_list.max()<0.05:\n",
    "          break\n",
    "        x=prob_list.argmax()\n",
    "        suggestion.append(word_list[x])\n",
    "        prob_list[x]=0\n",
    "      return suggestion\n",
    "  except IndexError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMT2Ic8XS_Eq"
   },
   "source": [
    "GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z5XQy20K4zkY"
   },
   "outputs": [],
   "source": [
    "def run_GUI():\n",
    "    \n",
    "  root=Tk()                                     \n",
    "  root.geometry('900x300')                       \n",
    "  root.config(bg='DodgerBlue4')\n",
    "  root.title('Automatic Text Generation: Test-box')\n",
    "  l1=Label(root,text='\\nAutomatic Text Generation: Test-box \\n  ',\n",
    "           font='Candara 18 bold',bg='DodgerBlue4',fg='SlateGray1')\n",
    "  l1.pack()\n",
    "  l2=Label(root)\n",
    "  global input_box\n",
    "  input_box=Entry(root,width=75,font='Candara 15',bg='SlateGray1')\n",
    "  input_box.pack()\n",
    "  global past\n",
    "  past=False\n",
    "  global lb\n",
    "  lb=Listbox()\n",
    "  import pyperclip\n",
    "  def copy():\n",
    "    pyperclip.copy(input_box.get())\n",
    "  Button(root,text='Copy',font='Candara 15',bg='DodgerBlue4',fg='SlateGray1',command=copy,relief='flat').pack(side=BOTTOM)\n",
    "  \n",
    "  def put(event):                                                               # Function to put selected word from...\n",
    "    global input_box                                                            # predicted words list into entry bar\n",
    "    input_text= str(input_box.get())\n",
    "    last_word=input_text.split()[-1]\n",
    "    cs = lb.curselection()    \n",
    "    insert_text= str(lb.get(cs))\n",
    "    if insert_text.startswith(last_word):\n",
    "      insert_text=insert_text[len(last_word):]\n",
    "    input_box.insert(END, insert_text + ' ')\n",
    "    lb.destroy()\n",
    "    suggestion = next_word(input_text+insert_text)\n",
    "    if len(suggestion) >0:\n",
    "        listing(suggestion)\n",
    "\n",
    "  def listing(predicted):                                                       # Function to print list of predicted words\n",
    "    global lb\n",
    "    lb = Listbox(root,font='Candara 15',width=15,height=len(predicted),bg='SlateGray1')\n",
    "    lb.bind('<Double-1>', put)\n",
    "    lb.pack()\n",
    "    for word in predicted:\n",
    "      lb.insert(END,word)\n",
    "    \n",
    "\n",
    "  def keypress(e):\n",
    "    global past\n",
    "    global lb\n",
    "    global l2\n",
    "    suggestion=[]\n",
    "    input_text=str(input_box.get())\n",
    "    if past==True:\n",
    "      lb.destroy()            \n",
    "    pyperclip.copy(input_box.get())\n",
    "    if e.char == ' ':                                                  # Prediction function called after <space>\n",
    "      suggestion=next_word(input_text)\n",
    "      past=True\n",
    "    else:\n",
    "      if past==True:\n",
    "        suggestion=curr_word(input_text)\n",
    "    \n",
    "    if len(suggestion)>0:\n",
    "      listing(suggestion)\n",
    "\n",
    "  root.bind(\"<KeyPress>\", keypress)\n",
    "  root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dHhXAz9t0UtJ"
   },
   "outputs": [],
   "source": [
    "root=Tk()\n",
    "root.geometry('830x500')\n",
    "root.config(bg='silver')\n",
    "def close(e):\n",
    "  root.destroy()\n",
    "Label(root,text=' '*10,font='Candara 45 bold',bg='silver').grid(row=0)\n",
    "Label(root,text=' '*10+'Project :',font='Candara 20 bold',bg='silver').grid(row=3,column=0,stick='w')\n",
    "Label(root,text=' '*10+'Automatic Text Generation',font='Candara 20 bold',bg='silver').grid(row=4,column=0,stick='e')\n",
    "Label(root,text=' '*10+'Developed By :',font='Candara 18 bold',fg='blue',bg='silver').grid(row=5,column=1,stick='sw')\n",
    "Label(root,text='Vaibhav Jain (181B232)',font='Candara 17 italic',fg='blue',bg='silver').grid(row=6,column=1,stick='e')\n",
    "Label(root,text='Vibhum Tripathi (181B237)',font='Candara 17 italic',fg='blue',bg='silver').grid(row=7,column=1,stick='e')\n",
    "Label(root,text='Mohit Sharma (181B129)',font='Candara 17 italic',fg='blue',bg='silver').grid(row=8,column=1,stick='e')\n",
    "Label(root,text=' '*10+'----'*16,font='Candara 17',fg='blue',bg='silver').grid(row=9,column=1)\n",
    "Label(root,text=' '*10+'Project Guide :',font='Candara 18 bold',fg='blue',bg='silver').grid(row=10,column=1,stick='w')\n",
    "Label(root,text='Dr. Ajay Kumar',font='Candara 17 italic',fg='blue',bg='silver').grid(row=11,column=1,stick='e')\n",
    "\n",
    "root.bind('<Motion>',close)\n",
    "root.mainloop()\n",
    " \n",
    "\n",
    "run_GUI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AutoTextGen_with_GUI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
